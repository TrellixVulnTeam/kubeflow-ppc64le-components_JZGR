{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f20b995-81e6-46ae-952a-f36267ee6cea",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "266a528d-a77c-460d-8b4c-3632170c702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.components import (\n",
    "    create_component_from_func,\n",
    "    OutputPath\n",
    ")\n",
    "from typing import (\n",
    "    Dict,\n",
    "    List,\n",
    "    NamedTuple\n",
    ")\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ibm/kubeflow-notebook-image-ppc64le:latest\"\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    path: str,\n",
    "    dataset_dir: OutputPath(str),\n",
    "    configuration: str = \"\",\n",
    "    label_columns: List[str] = None,\n",
    ") -> NamedTuple(\n",
    "        'LoadDatasetOutput', [\n",
    "            ('labels', Dict[str, List[str]])\n",
    "        ]):\n",
    "    '''\n",
    "    Load a Huggingface Dataset.\n",
    "\n",
    "            Parameters:\n",
    "                    path: Path from which to load the dataset. Huggingfaces hub for datasets is supported. Example: \"Lehrig/Monkey-Species-Collection\".\n",
    "                    dataset_dir: Target directory where the dataset will be loaded to. Should be available as a mount from a PVC. Example: \"/blackboard/dataset\".\n",
    "                    configuration: Name of the dataset configuration to load. Example: \"downsized\".\n",
    "                    label_columns: Optional list of label column names to be fetched as optional, additional output. Example: [\"label\"].\n",
    "            Returns:\n",
    "                    labels: Dictionary mapping label columns to associated labels, if available. Empty dictionary otherwise. Example: {\"labels\": [\"cat\", \"dog\"]}\n",
    "    '''\n",
    "\n",
    "    from collections import namedtuple\n",
    "    from datasets import load_dataset\n",
    "    from datasets.dataset_dict import DatasetDict\n",
    "    import logging\n",
    "    import os\n",
    "    from PIL.Image import Image\n",
    "    import sys\n",
    "\n",
    "    logging.basicConfig(\n",
    "        stream=sys.stdout,\n",
    "        level=logging.INFO,\n",
    "        format='%(levelname)s %(asctime)s: %(message)s'\n",
    "    )\n",
    "\n",
    "    if not configuration:\n",
    "        configuration = None\n",
    "    logging.info(f\"Loading dataset from '{path}' using configuration '{configuration}'...\")\n",
    "    dataset = load_dataset(path, configuration)\n",
    "\n",
    "    logging.info(\"Reading image files into bytes...\")\n",
    "\n",
    "    # see: https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk\n",
    "    def read_image_file(example):\n",
    "        for column in example:\n",
    "            if isinstance(example[column], Image):\n",
    "                with open(example[column].filename, \"rb\") as f:\n",
    "                    example[column] = {\"bytes\": f.read()}\n",
    "        return example\n",
    "\n",
    "    # note: batching in map caused caching issues, so not using it for now\n",
    "    dataset = dataset.map(read_image_file)\n",
    "\n",
    "    logging.info(f\"Saving dataset to '{dataset_dir}'...\")\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        os.makedirs(dataset_dir)\n",
    "    dataset.save_to_disk(dataset_dir)\n",
    "\n",
    "    logging.info(f\"Dataset saved. Contents of '{dataset_dir}':\")\n",
    "    logging.info(os.listdir(dataset_dir))\n",
    "\n",
    "    labels = dict()\n",
    "    if isinstance(dataset, DatasetDict):\n",
    "        dataset = next(iter(dataset.values()))\n",
    "        for label_column in label_columns:\n",
    "            logging.info(f\"Fetching labels from column '{label_column}'...\")\n",
    "            labels[label_column] = dataset.features[label_column].names\n",
    "\n",
    "    output = namedtuple(\n",
    "            'LoadDatasetOutput',\n",
    "            ['labels']\n",
    "        )\n",
    "\n",
    "    logging.info(\"Finished.\")\n",
    "    return output(labels)\n",
    "\n",
    "\n",
    "load_dataset_comp = create_component_from_func(\n",
    "    func=load_dataset,\n",
    "    output_component_file='component.yaml',\n",
    "    base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0960ca6-3f1a-4381-b08d-0b4b98fff112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'test'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dict()\n",
    "labels[\"key\"] = \"test\"\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63ca1ea-42eb-4c46-a9db-1fabce3af1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "output = namedtuple(\n",
    "            'LoadDatasetOutput',\n",
    "            ['labels']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb24c18-fdc3-4923-9826-611aded07cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadDatasetOutput(labels='{\"key\": \"test\"}')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "output(json.dumps(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66aa162d-18b5-4302-a109-e0666beb3c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadDatasetOutput(labels={'key': 'test'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee82e67-5174-4941-8367-1937ad33906c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
