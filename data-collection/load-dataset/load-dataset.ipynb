{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f20b995-81e6-46ae-952a-f36267ee6cea",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266a528d-a77c-460d-8b4c-3632170c702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.components import create_component_from_func\n",
    "from typing import (\n",
    "    List,\n",
    "    NamedTuple\n",
    ")\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ibm/kubeflow-notebook-image-ppc64le:latest\"\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    path: str,\n",
    "    blackboard_dir: str,\n",
    "    configuration: str = \"\",\n",
    "    label_column: str = \"\",\n",
    "    dataset_dir: str = \"/blackboard/dataset\",\n",
    ") -> NamedTuple(\n",
    "        'LoadDatasetOutput', [\n",
    "            ('dataset_dir', str),\n",
    "            ('labels', List[str])\n",
    "        ]):\n",
    "    '''\n",
    "    Load a Huggingface Dataset.\n",
    "\n",
    "            Parameters:\n",
    "                    path: Path from which to load the dataset. Huggingfaces hub for datasets is supported. Example: \"Lehrig/Monkey-Species-Collection\".\n",
    "                    blackboard_dir: Target directory of all data of a pipeline. Example: \"/blackboard\".\n",
    "                    configuration: Name of the dataset configuration to load. Example: \"downsized\".\n",
    "                    label_column: Optional name of a label column to be fetched as optional, additional output. Example: \"label\".\n",
    "                    dataset_dir: Target directory where the dataset will be loaded to. Should be available as a mount from a PVC. Example: \"/blackboard/dataset\".\n",
    "\n",
    "            Returns:\n",
    "                    dataset_dir: Target directory where the dataset will be loaded to. Same value as input dataset_dir. Example: \"/blackboard/dataset\".\n",
    "                    labels: List of labels, if available. Empty list otherwise. Example: [\"cat\", \"dog\"]\n",
    "    '''\n",
    "\n",
    "    from collections import namedtuple\n",
    "    from datasets import load_dataset\n",
    "    from datasets.dataset_dict import DatasetDict\n",
    "    import logging\n",
    "    import os\n",
    "    from PIL.Image import Image\n",
    "    import sys\n",
    "\n",
    "    logging.basicConfig(\n",
    "        stream=sys.stdout,\n",
    "        level=logging.INFO,\n",
    "        format='%(levelname)s %(asctime)s: %(message)s'\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(blackboard_dir):\n",
    "        raise ValueError(f\"Missing blackboard mount of a persistent volume (PV) into '{dataset_dir}'.\")\n",
    "\n",
    "    if not configuration:\n",
    "        configuration = None\n",
    "    logging.info(f\"Loading dataset from '{path}' using configuration '{configuration}'...\")\n",
    "    dataset = load_dataset(path, configuration)\n",
    "\n",
    "    logging.info(\"Reading image files into bytes...\")\n",
    "\n",
    "    # see: https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk\n",
    "    def read_image_file(example):\n",
    "        for column in example:\n",
    "            if isinstance(example[column], Image):\n",
    "                with open(example[column].filename, \"rb\") as f:\n",
    "                    example[column] = {\"bytes\": f.read()}\n",
    "        return example\n",
    "\n",
    "    # note: batching in map caused caching issues, so not using it for now\n",
    "    dataset = dataset.map(read_image_file)\n",
    "\n",
    "    logging.info(f\"Saving dataset to '{dataset_dir}'...\")\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        os.makedirs(dataset_dir)\n",
    "    dataset.save_to_disk(dataset_dir)\n",
    "\n",
    "    logging.info(f\"Dataset saved. Contents of '{dataset_dir}':\")\n",
    "    logging.info(os.listdir(dataset_dir))\n",
    "\n",
    "    labels = []\n",
    "    if label_column:\n",
    "        logging.info(f\"Fetching labels from column '{label_column}'...\")\n",
    "        if isinstance(dataset, DatasetDict):\n",
    "            dataset = next(iter(dataset.values()))\n",
    "        labels = dataset.features[label_column].names\n",
    "    output = namedtuple(\n",
    "            'LoadDatasetOutput',\n",
    "            ['dataset_dir',\n",
    "             'labels']\n",
    "        )\n",
    "\n",
    "    logging.info(\"Finished.\")\n",
    "    return output(dataset_dir, labels)\n",
    "\n",
    "\n",
    "load_dataset_comp = create_component_from_func(\n",
    "    func=load_dataset,\n",
    "    output_component_file='component.yaml',\n",
    "    base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0960ca6-3f1a-4381-b08d-0b4b98fff112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
