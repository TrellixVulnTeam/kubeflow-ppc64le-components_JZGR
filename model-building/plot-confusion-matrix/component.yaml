name: Plot confusion matrix
description: Plots a confusion matrix based on a Huggingface Dataset with a test split
  and a model trained via Keras.
inputs:
- {name: input_columns, type: 'typing.List[str]', description: 'Input columns for
    the model. Examples: ["mel_spectrogram", "pixel_values"].'}
- {name: label_columns, type: 'typing.Dict[str, typing.List[str]]', description: 'Dictionary
    mapping each label column to a list of possible labels. Example: {"genre": ["Blues",
    "Rock", "Country"]}'}
- {name: test_dataset_dir, type: String, description: 'Directory where to load test
    data from. Example: "/blackboard/prep_dataset".'}
- {name: model_dir, type: String, description: 'Directory where to load the model
    from. Example: "/blackboard/model".'}
- {name: dataset_split, type: String, description: Optional name of a dataset's split.
    Defaults to "test"., default: test, optional: true}
- {name: batch_size, type: Integer, description: 'Optional batch size when processing
    the input dataset. Example: 20.', default: '20', optional: true}
outputs:
- {name: mlpipeline_ui_metadata}
implementation:
  container:
    image: quay.io/ibm/kubeflow-notebook-image-ppc64le:latest
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n   \
      \ os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
      \ndef plot_confusion_matrix(\n        input_columns,\n        label_columns,\n\
      \        test_dataset_dir,\n        model_dir,\n        mlpipeline_ui_metadata_path,\n\
      \        dataset_split = \"test\",\n        batch_size = 20\n):\n    '''\n \
      \   Plots a confusion matrix based on a Huggingface Dataset with a test split\
      \ and a model trained via Keras.\n\n            Parameters:\n              \
      \      input_columns: Input columns for the model. Examples: [\"mel_spectrogram\"\
      , \"pixel_values\"].\n                    label_columns: Dictionary mapping\
      \ each label column to a list of possible labels. Example: {\"genre\": [\"Blues\"\
      , \"Rock\", \"Country\"]}\n                    test_dataset_dir: Directory where\
      \ to load test data from. Example: \"/blackboard/prep_dataset\".\n         \
      \           model_dir: Directory where to load the model from. Example: \"/blackboard/model\"\
      .\n                    dataset_split: Optional name of a dataset's split. Defaults\
      \ to \"test\".\n                    batch_size: Optional batch size when processing\
      \ the input dataset. Example: 20.\n            Returns:\n                  \
      \  mlpipeline_ui_metadata_path: Data to plot a confusion matrix. The plotted\
      \ confusion matrix can be viewed via Kubeflow UI's Vizualization for this component\
      \ inside a pipeline run.\n    '''\n    from collections.abc import Iterable\n\
      \    import json\n    import logging\n    import numpy as np\n    import pandas\
      \ as pd\n    import sys\n    import tensorflow as tf\n\n    logging.basicConfig(\n\
      \        stream=sys.stdout,\n        level=logging.INFO,\n        format='%(levelname)s\
      \ %(asctime)s: %(message)s'\n    )\n    logger = logging.getLogger()\n\n   \
      \ test_dataset = tf.data.experimental.load(test_dataset_dir)\n\n    model =\
      \ tf.keras.models.load_model(model_dir)\n\n    # see: https://github.com/huggingface/datasets/issues/4772\n\
      \    if \"labels\" in label_columns:\n        label_columns[\"label\"] = label_columns.pop(\"\
      labels\")\n\n    def ensure_encoding(label_tensor):\n        rank = label_tensor.shape.rank\n\
      \n        if rank != 1 and rank != 2:\n            err = f\"Rank of label tensor\
      \ has to be 1 or 2 but found rank {rank}!\"\n            logger.error(err)\n\
      \            raise Exception(err)\n\n        # transform one-hot vector into\
      \ integer\n        return tf.math.argmax(\n                label_tensor,\n \
      \               axis=rank-1\n            )\n\n    def prediction_to_encoded_tensor(prediction):\n\
      \        result = None\n        if isinstance(prediction, np.ndarray):\n   \
      \         if len(prediction) == 1:\n                pred = prediction[0]\n \
      \               if isinstance(pred, np.ndarray):\n                    if len(pred)\
      \ == 1:\n                        result = round(pred[0])\n                 \
      \   elif len(pred) > 1: \n                        result.append(np.argmax(pred,\
      \ axis=0))\n                    else:\n                        err = f\"Unsupport\
      \ prediction array size: {len(pred[0])}\"\n                        logger.error(err)\n\
      \                        raise Exception(err)\n                elif isinstance(pred,\
      \ (np.floating, float)):\n                    result.append(round(pred))\n \
      \               elif isinstance(pred, (np.integer, int)):\n                \
      \    result.append(pred)\n                else:\n                    err = f\"\
      Unsupport prediction type: {type(pred)}\"\n                    logger.error(err)\n\
      \                    raise Exception(err)\n            elif len(prediction)\
      \ > 1: \n                result = np.argmax(prediction, axis=0)\n          \
      \  else:\n                err = f\"Unsupport prediction length: {len(prediction)}\"\
      \n                logger.error(err)\n                raise Exception(err)\n\
      \        elif isinstance(prediction, tf.Tensor):\n            result = ensure_encoding(prediction)\n\
      \        elif isinstance(prediction, (np.floating, float)):\n            result\
      \ = round(prediction)\n        elif isinstance(prediction, (np.integer, int)):\n\
      \            result = prediction\n        else:\n            err = f\"Unsupport\
      \ model prediction type: {type(prediction)}\"\n            logger.error(err)\n\
      \            raise Exception(err)\n\n        if isinstance(result, tf.Tensor):\n\
      \            if len(result.shape) == 0:\n                result = [result]\n\
      \        elif isinstance(result, dict) or isinstance(result, list):\n      \
      \      if len(result) == 0:\n                result = [result]\n        elif\
      \ isinstance(result, (np.integer, int)):\n            result = [result]\n  \
      \      else:\n            err = f\"Unsupport result type: {len(result)}\"\n\
      \            logger.error(err)\n            raise Exception(err)\n\n       \
      \ return result\n\n    def merge_to_dict(dictionary, key, tensor):\n       \
      \ if key in dictionary:\n            dictionary[key] = tf.concat([dictionary.pop(key),\
      \ tensor], axis=0)\n        else:\n            dictionary[key] = tensor\n\n\
      \    def process_tensors(dictionary, tensors, label_columns, index2label):\n\
      \        if isinstance(tensors, dict):\n            # Multi-label support\n\
      \            for key, tensor in tensors.items():\n                encoded_tensor\
      \ = prediction_to_encoded_tensor(tensor)\n                merge_to_dict(dictionary,\
      \ key, encoded_tensor)\n        elif isinstance(tensors, list) or isinstance(tensors,\
      \ np.ndarray):\n            # Multi-label support; assume order & get name from\
      \ dataset\n            for idx, tensor in enumerate(tensors):\n            \
      \    encoded_tensor = prediction_to_encoded_tensor(tensor)\n               \
      \ if len(index2label) == 1:\n                    label = index2label[0]\n  \
      \              else:\n                    label = index2label[idx]\n       \
      \         merge_to_dict(dictionary, label, encoded_tensor)\n        elif isinstance(tensors,\
      \ tf.Tensor):\n            # Assuming single label\n            if len(label_columns)\
      \ > 1:\n                err = f\"Model provides only 1 output but got {len(label_columns)}\
      \ label columns!\"\n                logger.error(err)\n                raise\
      \ Exception(err)\n            key = next(iter(label_columns))\n\n          \
      \  for tensor in tensors:\n                encoded_tensor = prediction_to_encoded_tensor(tensor)\n\
      \                merge_to_dict(dictionary, key, encoded_tensor)\n        else:\n\
      \            err = f\"Unsupported tensors type: {type(tensors)}!\"\n       \
      \     logger.error(err)\n            raise Exception(err)\n\n    # Get label\
      \ indexes & names from dataset\n    index2label = dict()\n    label_specs =\
      \ test_dataset.element_spec[1]\n    if isinstance(label_specs, Iterable):\n\
      \        for i, label in enumerate(label_specs):\n            index2label[i]\
      \ = label\n    else:\n        # Fall-back to Huggingface dataset\n        for\
      \ i, label in enumerate(label_columns):\n            index2label[i] = label\n\
      \    logging.info(f\"Indexes mapped to labels: {index2label}\")\n\n    # each\
      \ dataset_batch is of size batch_size; results are aggregate inside this loop\n\
      \    y_true = dict()\n    y_pred = dict()\n    for dataset_batch in test_dataset:\n\
      \        label_tensors = dataset_batch[1]\n        process_tensors(y_true, label_tensors,\
      \ label_columns, index2label)\n\n        feature_tensors = dataset_batch[0]\n\
      \        predictions = model.predict(feature_tensors)\n        process_tensors(y_pred,\
      \ predictions, label_columns, index2label)\n\n    logging.info(f\"Final labels:\
      \ {y_true}\")\n    logging.info(f\"Final predictions: {y_pred}\")\n\n    confusion_matrices\
      \ = []\n    for label_column, labels in label_columns.items():\n        confusion_matrix\
      \ = tf.math.confusion_matrix(\n            labels=y_true[label_column],\n  \
      \          predictions=y_pred[label_column],\n            num_classes=len(labels))\n\
      \n        data = []\n        for target_index, target_row in enumerate(confusion_matrix):\n\
      \            for predicted_index, count in enumerate(target_row):\n        \
      \        data.append((labels[target_index], labels[predicted_index], count.numpy()))\n\
      \n        df = pd.DataFrame(\n            data,\n            columns=['target',\
      \ 'predicted', 'count']\n        )\n\n        confusion_matrices.append({\n\
      \            'type': 'confusion_matrix',\n            'format': 'csv',\n   \
      \         'schema': [\n              {'name': 'target', 'type': 'CATEGORY'},\n\
      \              {'name': 'predicted', 'type': 'CATEGORY'},\n              {'name':\
      \ 'count', 'type': 'NUMBER'},\n            ],\n            \"storage\": \"inline\"\
      ,\n            'source': df.to_csv(\n                columns=['target', 'predicted',\
      \ 'count'],\n                header=False,\n                index=False),\n\
      \            'labels': labels,\n        })\n\n    metadata = {\n      'outputs':\
      \ confusion_matrices\n    }\n\n    logger.info(\"Dumping mlpipeline_ui_metadata...\"\
      )\n    with open(mlpipeline_ui_metadata_path, 'w') as metadata_file:\n     \
      \   json.dump(metadata, metadata_file)\n\n    logger.info(\"Finished.\")\n\n\
      import json\nimport argparse\n_parser = argparse.ArgumentParser(prog='Plot confusion\
      \ matrix', description='Plots a confusion matrix based on a Huggingface Dataset\
      \ with a test split and a model trained via Keras.')\n_parser.add_argument(\"\
      --input-columns\", dest=\"input_columns\", type=json.loads, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--label-columns\", dest=\"label_columns\", type=json.loads,\
      \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--test-dataset-dir\"\
      , dest=\"test_dataset_dir\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--model-dir\", dest=\"model_dir\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--dataset-split\", dest=\"\
      dataset_split\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --batch-size\", dest=\"batch_size\", type=int, required=False, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--mlpipeline-ui-metadata\", dest=\"mlpipeline_ui_metadata_path\"\
      , type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n\
      _parsed_args = vars(_parser.parse_args())\n\n_outputs = plot_confusion_matrix(**_parsed_args)\n"
    args:
    - --input-columns
    - {inputValue: input_columns}
    - --label-columns
    - {inputValue: label_columns}
    - --test-dataset-dir
    - {inputPath: test_dataset_dir}
    - --model-dir
    - {inputPath: model_dir}
    - if:
        cond: {isPresent: dataset_split}
        then:
        - --dataset-split
        - {inputValue: dataset_split}
    - if:
        cond: {isPresent: batch_size}
        then:
        - --batch-size
        - {inputValue: batch_size}
    - --mlpipeline-ui-metadata
    - {outputPath: mlpipeline_ui_metadata}
